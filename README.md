# ğŸ“˜ Projeto de Engenharia de Dados â€“ Azure, Databricks e ADF

## ğŸš€ Objetivos do Projeto

- âœ”ï¸ ConstruÃ­ um **pipeline completo de Engenharia de Dados**
- âœ”ï¸ Estruturei um **Data Lake** utilizando **Azure Data Lake Storage Gen2**
- âœ”ï¸ Configurei o **Azure Databricks** integrado ao ambiente em nuvem
- âœ”ï¸ Desenvolvi notebooks no Databricks utilizando **Scala**
- âœ”ï¸ Criei pipelines de ingestÃ£o e transformaÃ§Ã£o no **Azure Data Factory (ADF)**
- âœ”ï¸ Integrei o projeto completo com o **GitHub** para versionamento
- âœ”ï¸ Configurei **gatilhos de execuÃ§Ã£o** para automatizar o pipeline
- âœ”ï¸ Coloquei todo o fluxo em **produÃ§Ã£o** no Azure

---

## ğŸ—‚ï¸ Arquitetura do Projeto

A soluÃ§Ã£o que implementei utiliza os seguintes serviÃ§os da Azure:

- **Azure Data Lake Storage Gen2** â†’ armazenamento em camadas (Bronze, Silver)  
- **Azure Databricks** â†’ processamento distribuÃ­do via notebooks em Scala  
- **Azure Data Factory** â†’ orquestraÃ§Ã£o das atividades  
- **GitHub** â†’ versionamento de notebooks e pipelines  
- **Triggers do ADF** â†’ automaÃ§Ã£o de execuÃ§Ãµes

### ğŸ”„ Fluxo resumido da soluÃ§Ã£o

1. **IngestÃ£o** â†’ Carrego dados brutos na camada Bronze do Data Lake  
2. **TransformaÃ§Ã£o** â†’ Processos no Databricks geram as camadas Silver e Gold  
3. **OrquestraÃ§Ã£o** â†’ O Azure Data Factory coordena todas as etapas  
4. **Versionamento (CI/CD)** â†’ GitHub controla mudanÃ§as e histÃ³rico  
5. **ProduÃ§Ã£o** â†’ O pipeline roda automaticamente via triggers

## ğŸ”§ Tecnologias e Ferramentas que utilizei

- **Azure Data Lake Storage Gen2**
- **Azure Databricks**
- **Scala**
- **Azure Data Factory**
- **GitHub**
- **Azure Monitor (opcional)**
- **Triggers do ADF**

---

## â–¶ï¸ Como executo o pipeline

1. **ConfiguraÃ§Ã£o do Data Lake**  
   - Criei a Storage Account  
   - Ativei o *Hierarchical Namespace*  
   - Estruturei os containers bronze/silver

2. **ConfiguraÃ§Ã£o do Databricks**  
   - Configurei o workspace e o cluster  
   - Fiz a integraÃ§Ã£o com o Data Lake via ABFS  
   - Desenvolvi os notebooks em Scala

3. **ConstruÃ§Ã£o dos Pipelines no ADF**  
   - Modelei as etapas de ingestÃ£o, transformaÃ§Ã£o e movimentaÃ§Ã£o  
   - Conectei atividades e notebooks

4. **IntegraÃ§Ã£o com o GitHub**  
   - Versionei notebooks  
   - Versionei pipelines do ADF

5. **ConfiguraÃ§Ã£o dos Triggers**  
   - Programei gatilhos para execuÃ§Ã£o automÃ¡tica

---

## ğŸ“¦ Deploy em ProduÃ§Ã£o

Para finalizar o projeto, eu:

- Publiquei os pipelines no Azure Data Factory  
- Ativei os triggers  
- Realizei testes de execuÃ§Ã£o  
- Monitorei logs e alertas pelo ADF Monitor e Azure Monitor

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais.

